{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["WtcRFs2Agzga","b_I6v9okv02M","D-N8QRu7v5ws","ImCaePOUv6oi"],"authorship_tag":"ABX9TyMjr38Y9/kc32+GjqPjkfMm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["> **Live Demo**\n","> ---\n","\n","Here we will extract the generated optimal parameters from the saved file to reduce time needed to present the results. We will present 20 images results each.\n"],"metadata":{"id":"mrCpCSRQmZ_F"}},{"cell_type":"markdown","source":["# Imports, Data and Functions\n","\n","Importing essential packages, loading image data and defining necessary functions"],"metadata":{"id":"WtcRFs2Agzga"}},{"cell_type":"code","source":["!pip install scikit-optimize"],"metadata":{"id":"aYvrQUTkgzgb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733545792110,"user_tz":-540,"elapsed":13000,"user":{"displayName":"Bettina Tee","userId":"07268329748509248306"}},"outputId":"bfb021c9-3f2a-4970-a056-95866a3fb8c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-optimize\n","  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n","Collecting pyaml>=16.9 (from scikit-optimize)\n","  Downloading pyaml-24.9.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.5.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n","Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyaml-24.9.0-py3-none-any.whl (24 kB)\n","Installing collected packages: pyaml, scikit-optimize\n","Successfully installed pyaml-24.9.0 scikit-optimize-0.10.2\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import random\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import scipy.io as sio\n","from tqdm import tqdm\n","\n","from PIL import Image, ImageEnhance\n","from skimage.util import img_as_float\n","from skimage.color import rgb2gray\n","from skimage.io import imread, imsave\n","from skimage.measure import shannon_entropy\n","from skimage.feature import local_binary_pattern\n","import cv2\n","\n","from sklearn.metrics import f1_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.multioutput import MultiOutputClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","from skopt import gp_minimize\n","from skopt.space import Categorical\n","\n","from google.colab import drive"],"metadata":{"id":"GigXCl4Lgzgb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["drive.mount(\"/content/drive\")"],"metadata":{"id":"8Kk7Iovagzgb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733545843070,"user_tz":-540,"elapsed":40912,"user":{"displayName":"Bettina Tee","userId":"07268329748509248306"}},"outputId":"602c9578-5857-4119-cefb-65f87ee13a11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# data_dir = # \"PATH_TO_YOUR_FOLDER\"\n","\n","# Checking if our specified directory exists\n","os.path.exists(data_dir)"],"metadata":{"id":"BInx07a0gzgc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733545843328,"user_tz":-540,"elapsed":262,"user":{"displayName":"Bettina Tee","userId":"07268329748509248306"}},"outputId":"4526bc8e-b428-48f9-f553-e87f55b23bb5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["class BoundaryDataset(object):\n","    \"\"\"\n","    Project boundary dataset wrapper\n","\n","    Given the path to the root of the dataset, this class provides\n","    methods for loading images and ground truths.\n","\n","    Attributes:\n","\n","    root_dir - the root path of the dataset\n","    data_path - the path of the data directory within the root\n","    sample_names - a list of names of images\n","    \"\"\"\n","    def __init__(self, root_dir='.', split='train'):\n","        \"\"\"\n","        Constructor\n","\n","        :param root_dir: the path to the root of the custom dataset\n","        :param split: 'train' or 'test'\n","        \"\"\"\n","        self.root_dir = root_dir\n","        self.data_path = os.path.join(root_dir, split)\n","        self.sample_names = self._sample_names(self.data_path)\n","\n","    def __len__(self):\n","        \"\"\"\n","        Get the number of samples in the dataset\n","        :return: the number of samples\n","        \"\"\"\n","        return len(self.sample_names)\n","\n","    @staticmethod\n","    def _sample_names(directory):\n","        names = []\n","        files = os.listdir(directory)\n","        for fn in files:\n","            name, ext = os.path.splitext(fn)\n","            if ext.lower() == '.jpg':\n","                names.append(name)\n","        return names\n","\n","    def read_image(self, name):\n","        \"\"\"\n","        Load the image identified by the sample name\n","        :param name: the sample name\n","        :return: a (H,W,3) array containing the image\n","        \"\"\"\n","        path = os.path.join(self.data_path, f\"{name}.jpg\")\n","        return imread(path)\n","\n","    def load_boundaries(self, name):\n","        \"\"\"\n","        Load the boundaries identified by the sample name\n","        :param name: the sample name\n","        :return: a list of (H,W) arrays, each of which contains a boundary ground truth\n","        \"\"\"\n","        boundary_path = os.path.join(self.data_path, f\"{name}.npy\")\n","        if os.path.exists(boundary_path):\n","            boundaries = np.load(boundary_path, allow_pickle=True)\n","            return list(boundaries)\n","        return []"],"metadata":{"id":"fGUmwiYLgzgc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["split = 'train'\n","\n","# Load the dataset using BoundaryDataset class\n","train_dataset = BoundaryDataset(data_dir + \"/project_data\", split=split)\n","\n","print(f\"Data size: {len(train_dataset)}\")"],"metadata":{"id":"2riAcIr9gzgd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733545844638,"user_tz":-540,"elapsed":1312,"user":{"displayName":"Bettina Tee","userId":"07268329748509248306"}},"outputId":"3bd63b98-f48c-4ed5-d05c-1afd6f7dd685"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data size: 200\n"]}]},{"cell_type":"code","source":["split = 'test'\n","\n","# Load the dataset using BoundaryDataset class\n","test_dataset = BoundaryDataset(data_dir + \"/project_data\", split=split)\n","\n","print(f\"Data size: {len(test_dataset)}\")"],"metadata":{"id":"9Qwaax0ogE6W","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1733545844896,"user_tz":-540,"elapsed":261,"user":{"displayName":"Bettina Tee","userId":"07268329748509248306"}},"outputId":"cc630803-ef32-4acf-b79e-dd1d135385d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Data size: 100\n"]}]},{"cell_type":"code","source":["# Function to generate edges for each channel (RGB) and combine them\n","def generate_edges_rgb(image, blur_amounts, sigmas, contrast_factors):\n","    # Separate the channels\n","    red_channel = image[:, :, 2]  # Red channel\n","    green_channel = image[:, :, 1]  # Green channel\n","    blue_channel = image[:, :, 0]  # Blue channel\n","\n","    # Process each channel independently\n","    def process_channel(channel, blur_amount, sigma, contrast_factor):\n","\n","        blurred = cv2.GaussianBlur(channel, (blur_amount, blur_amount), sigma)\n","\n","        img_pil = Image.fromarray(blurred)\n","        enhanced_img_pil = ImageEnhance.Contrast(img_pil).enhance(contrast_factor)\n","        enhanced_img = np.array(enhanced_img_pil)\n","\n","        grad_x = cv2.Sobel(enhanced_img, cv2.CV_64F, 1, 0, ksize=3)\n","        grad_y = cv2.Sobel(enhanced_img, cv2.CV_64F, 0, 1, ksize=3)\n","        gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n","\n","        # Normalize the gradient magnitude to [0, 1]\n","        gradient_magnitude_min = np.min(gradient_magnitude)\n","        gradient_magnitude_max = np.max(gradient_magnitude)\n","        normalized_gradient = (gradient_magnitude - gradient_magnitude_min) / (gradient_magnitude_max - gradient_magnitude_min)\n","\n","        return normalized_gradient\n","\n","    red_edges = process_channel(red_channel, blur_amounts[0], sigmas[0], contrast_factors[0])\n","    green_edges = process_channel(green_channel, blur_amounts[1], sigmas[1], contrast_factors[1])\n","    blue_edges = process_channel(blue_channel, blur_amounts[2], sigmas[2], contrast_factors[2])\n","\n","    # Combine the edges from all channels\n","    combined_edges = np.maximum.reduce([red_edges, green_edges, blue_edges])\n","\n","    return combined_edges"],"metadata":{"id":"IHrEXymBgzgd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Presenting Results"],"metadata":{"id":"b_I6v9okv02M"}},{"cell_type":"markdown","source":["## Train\n","\n","Presenting Image, Boundaries and Predicted Edges for train images"],"metadata":{"id":"D-N8QRu7v5ws"}},{"cell_type":"code","source":["optimal_parameters = np.load(os.path.join(data_dir, 'saved_variables', 'optimal_parameters_train.npy'), allow_pickle=True).item()\n","selected_sample_names = train_dataset.sample_names[:20]\n","\n","for selected_sample_name in selected_sample_names:\n","    print(f\"Processing image: {split}/{selected_sample_name}\")\n","    image = train_dataset.read_image(selected_sample_name)\n","    boundaries = train_dataset.load_boundaries(selected_sample_name)\n","\n","    # retrieve optimal parameters that were predicted\n","    blur_amounts, sigmas, contrast_factors = optimal_parameters[selected_sample_name]\n","\n","    # generate edges based on optimal parameters\n","    edges = generate_edges_rgb(image, blur_amounts, sigmas, contrast_factors)\n","\n","    # display image\n","    fig, ax = plt.subplots(1, 5, figsize=(10, 8))\n","    ax[0].imshow(image)\n","    ax[0].set_title(\"Original Image\")\n","    ax[0].axis(\"off\")\n","\n","    # display boundaries (ground truth)\n","    for i in range(len(boundaries)):\n","        ax[i + 1].imshow(boundaries[i], cmap='gray')\n","        ax[i + 1].set_title(f\"Boundary {i + 1}\")\n","        ax[i + 1].axis(\"off\")\n","        edge_count = np.sum(boundaries[i] > 0)\n","        edge_density = edge_count / (boundaries[i].size)\n","\n","    # display extracted edges\n","    ax[4].imshow(edges, cmap='gray')\n","    ax[4].set_title(\"Extracted Edge Strength\")\n","    ax[4].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"aO8xjmUOvJS0","colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"19AqeTK7NcZ_jRsrTm_EgEHAaCwsQiS1o"},"executionInfo":{"status":"ok","timestamp":1733545865215,"user_tz":-540,"elapsed":20321,"user":{"displayName":"Bettina Tee","userId":"07268329748509248306"}},"outputId":"de3c7bbf-b87a-4fde-daec-9ed3d462615b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["## Test\n","\n","Presenting Image and Predicted Edges for train images"],"metadata":{"id":"ImCaePOUv6oi"}},{"cell_type":"code","source":["optimal_parameters = np.load(os.path.join(data_dir, 'saved_variables', 'optimal_parameters.npy'), allow_pickle=True).item()\n","selected_sample_names = test_dataset.sample_names[:20]\n","\n","for selected_sample_name in selected_sample_names:\n","    print(f\"Processing image: {split}/{selected_sample_name}\")\n","    image = test_dataset.read_image(selected_sample_name)\n","\n","    # retrieve optimal parameters\n","    blur_amounts, sigmas, contrast_factors = optimal_parameters[selected_sample_name]\n","\n","    # generate edges based on optimal parameters\n","    edges = generate_edges_rgb(image, blur_amounts, sigmas, contrast_factors)\n","\n","    # display images and boundaries and extracted edges\n","    fig, ax = plt.subplots(1, 2, figsize=(5, 3))\n","    ax[0].imshow(image)\n","    ax[0].set_title(\"Original Image\")\n","    ax[0].axis(\"off\")\n","\n","    ax[1].imshow(edges, cmap='gray')\n","    ax[1].set_title(\"Extracted Edge Strength\")\n","    ax[1].axis(\"off\")\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"tbvpkUPYu_9G","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1KpfhI42wSDxsiRRipUWn-pScvyCGGuSv"},"executionInfo":{"status":"ok","timestamp":1733545877285,"user_tz":-540,"elapsed":12092,"user":{"displayName":"Bettina Tee","userId":"07268329748509248306"}},"outputId":"d4495745-29ff-421c-cc97-5eb0a88b6568"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}